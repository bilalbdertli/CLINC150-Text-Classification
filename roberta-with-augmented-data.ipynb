{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10380570,"sourceType":"datasetVersion","datasetId":6430426},{"sourceId":10382957,"sourceType":"datasetVersion","datasetId":6431914}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer, TFAutoModelForSequenceClassification\nfrom datasets import load_dataset, DatasetDict\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:43:45.028366Z","iopub.execute_input":"2025-01-06T08:43:45.028674Z","iopub.status.idle":"2025-01-06T08:43:57.795160Z","shell.execute_reply.started":"2025-01-06T08:43:45.028649Z","shell.execute_reply":"2025-01-06T08:43:57.794256Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"label_to_id = {\n    \"restaurant_reviews\": 0,\n    \"nutrition_info\": 1,\n    \"account_blocked\": 2,\n    \"oil_change_how\": 3,\n    \"time\": 4,\n    \"weather\": 5,\n    \"redeem_rewards\": 6,\n    \"interest_rate\": 7,\n    \"gas_type\": 8,\n    \"accept_reservations\": 9,\n    \"smart_home\": 10,\n    \"user_name\": 11,\n    \"report_lost_card\": 12,\n    \"repeat\": 13,\n    \"whisper_mode\": 14,\n    \"what_are_your_hobbies\": 15,\n    \"order\": 16,\n    \"jump_start\": 17,\n    \"schedule_meeting\": 18,\n    \"meeting_schedule\": 19,\n    \"freeze_account\": 20,\n    \"what_song\": 21,\n    \"meaning_of_life\": 22,\n    \"restaurant_reservation\": 23,\n    \"traffic\": 24,\n    \"make_call\": 25,\n    \"text\": 26,\n    \"bill_balance\": 27,\n    \"improve_credit_score\": 28,\n    \"change_language\": 29,\n    \"no\": 30,\n    \"measurement_conversion\": 31,\n    \"timer\": 32,\n    \"flip_coin\": 33,\n    \"do_you_have_pets\": 34,\n    \"balance\": 35,\n    \"tell_joke\": 36,\n    \"last_maintenance\": 37,\n    \"exchange_rate\": 38,\n    \"uber\": 39,\n    \"car_rental\": 40,\n    \"credit_limit\": 41,\n    \"change_volume\": 42,\n    \"shopping_list\": 43,\n    \"expiration_date\": 44,\n    \"routing\": 45,\n    \"meal_suggestion\": 46,\n    \"tire_change\": 47,\n    \"todo_list\": 48,\n    \"card_declined\": 49,\n    \"rewards_balance\": 50,\n    \"change_accent\": 51,\n    \"vaccines\": 52,\n    \"reminder_update\": 53,\n    \"food_last\": 54,\n    \"change_ai_name\": 55,\n    \"bill_due\": 56,\n    \"who_do_you_work_for\": 57,\n    \"share_location\": 58,\n    \"international_visa\": 59,\n    \"calendar\": 60,\n    \"translate\": 61,\n    \"carry_on\": 62,\n    \"book_flight\": 63,\n    \"insurance_change\": 64,\n    \"todo_list_update\": 65,\n    \"timezone\": 66,\n    \"cancel_reservation\": 67,\n    \"transactions\": 68,\n    \"credit_score\": 69,\n    \"report_fraud\": 70,\n    \"spending_history\": 71,\n    \"directions\": 72,\n    \"spelling\": 73,\n    \"insurance\": 74,\n    \"what_is_your_name\": 75,\n    \"reminder\": 76,\n    \"where_are_you_from\": 77,\n    \"distance\": 78,\n    \"payday\": 79,\n    \"flight_status\": 80,\n    \"find_phone\": 81,\n    \"greeting\": 82,\n    \"alarm\": 83,\n    \"order_status\": 84,\n    \"confirm_reservation\": 85,\n    \"cook_time\": 86,\n    \"damaged_card\": 87,\n    \"reset_settings\": 88,\n    \"pin_change\": 89,\n    \"replacement_card_duration\": 90,\n    \"new_card\": 91,\n    \"roll_dice\": 92,\n    \"income\": 93,\n    \"taxes\": 94,\n    \"date\": 95,\n    \"who_made_you\": 96,\n    \"pto_request\": 97,\n    \"tire_pressure\": 98,\n    \"how_old_are_you\": 99,\n    \"rollover_401k\": 100,\n    \"pto_request_status\": 101,\n    \"how_busy\": 102,\n    \"application_status\": 103,\n    \"recipe\": 104,\n    \"calendar_update\": 105,\n    \"play_music\": 106,\n    \"yes\": 107,\n    \"direct_deposit\": 108,\n    \"credit_limit_change\": 109,\n    \"gas\": 110,\n    \"pay_bill\": 111,\n    \"ingredients_list\": 112,\n    \"lost_luggage\": 113,\n    \"goodbye\": 114,\n    \"what_can_i_ask_you\": 115,\n    \"book_hotel\": 116,\n    \"are_you_a_bot\": 117,\n    \"next_song\": 118,\n    \"change_speed\": 119,\n    \"plug_type\": 120,\n    \"maybe\": 121,\n    \"w2\": 122,\n    \"oil_change_when\": 123,\n    \"thank_you\": 124,\n    \"shopping_list_update\": 125,\n    \"pto_balance\": 126,\n    \"order_checks\": 127,\n    \"travel_alert\": 128,\n    \"fun_fact\": 129,\n    \"sync_device\": 130,\n    \"schedule_maintenance\": 131,\n    \"apr\": 132,\n    \"transfer\": 133,\n    \"ingredient_substitution\": 134,\n    \"calories\": 135,\n    \"current_location\": 136,\n    \"international_fees\": 137,\n    \"calculator\": 138,\n    \"definition\": 139,\n    \"next_holiday\": 140,\n    \"update_playlist\": 141,\n    \"mpg\": 142,\n    \"min_payment\": 143,\n    \"change_user_name\": 144,\n    \"restaurant_suggestion\": 145,\n    \"travel_notification\": 146,\n    \"cancel\": 147,\n    \"pto_used\": 148,\n    \"travel_suggestion\": 149,\n}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:43:57.796300Z","iopub.execute_input":"2025-01-06T08:43:57.796971Z","iopub.status.idle":"2025-01-06T08:43:57.806931Z","shell.execute_reply.started":"2025-01-06T08:43:57.796938Z","shell.execute_reply":"2025-01-06T08:43:57.805907Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"dataset = load_dataset(\"clinc/clinc_oos\", \"plus\")\ndef filter_intent(example):\n    return example['intent'] != 42\n\n# Apply the filter function to each split to remove OOS queries\ndataset = DatasetDict({\n    split: dataset[split].filter(filter_intent)\n    for split in dataset\n})\n# Now we need to update the labels so that our model does not give an error. \ndef update_intent(example):\n    if example['intent'] == 150:\n        example['intent'] = 42\n    return example\n\ndataset = DatasetDict({\n    split: dataset[split].map(update_intent)\n    for split in dataset\n})\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:43:57.808715Z","iopub.execute_input":"2025-01-06T08:43:57.808985Z","iopub.status.idle":"2025-01-06T08:44:03.123973Z","shell.execute_reply.started":"2025-01-06T08:43:57.808965Z","shell.execute_reply":"2025-01-06T08:44:03.123158Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/24.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80a011e55f9048228987cf664e4d62c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/312k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51746ba8c05745089299cea5fdb465f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"validation-00000-of-00001.parquet:   0%|          | 0.00/77.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33031db7c18640c1a16e9b80db00432f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/136k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"132f2f422be849d5b03c807fb9ee9634"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/15250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c928ba486104a689ecab89040ff975d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/3100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b15f733c04c44709420782f810921d9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e733fe7eaac43688568a7b8068136f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/15250 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ec29ac0e86f471bb34f2c423860a473"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/3100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"379aaf07e4a34fc2b27a29ad35c9e085"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/5500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3f591ec07f14394a9f687d5d41616c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/15000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09cb7f837b43426f96bb7af0b1943249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47b17c2894174a17b625899633157622"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4b7d32b81964ac5ada07f1cae81fbd6"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'intent'],\n        num_rows: 15000\n    })\n    validation: Dataset({\n        features: ['text', 'intent'],\n        num_rows: 3000\n    })\n    test: Dataset({\n        features: ['text', 'intent'],\n        num_rows: 4500\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"import json\nfrom datasets import Dataset\n# Load the dataset\nfile_path = \"/kaggle/input/augmented-dataset-new/augmented_dataset_new.json\"\n\nfiltered_data = []\n\nwith open(file_path, 'r', encoding='utf-8') as file:\n    for line in file:\n        record = json.loads(line.strip())\n        intent_id = label_to_id[record[\"intent\"]]\n        # Extract only 'query' and 'intent'\n        filtered_data.append({\"query\": record[\"query\"], \"intent\": intent_id})\n\n# Convert to Hugging Face Dataset\nfiltered_data = Dataset.from_list(filtered_data)\n\n# Inspect the Dataset\nprint(len(filtered_data))\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.125156Z","iopub.execute_input":"2025-01-06T08:44:03.125383Z","iopub.status.idle":"2025-01-06T08:44:03.279353Z","shell.execute_reply.started":"2025-01-06T08:44:03.125362Z","shell.execute_reply":"2025-01-06T08:44:03.278466Z"}},"outputs":[{"name":"stdout","text":"28860\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"filtered_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.280239Z","iopub.execute_input":"2025-01-06T08:44:03.280458Z","iopub.status.idle":"2025-01-06T08:44:03.285326Z","shell.execute_reply.started":"2025-01-06T08:44:03.280438Z","shell.execute_reply":"2025-01-06T08:44:03.284618Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['query', 'intent'],\n    num_rows: 28860\n})"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"filtered_data = filtered_data.rename_column('query', 'text')\nfiltered_data = filtered_data.rename_column('intent', 'label')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.286180Z","iopub.execute_input":"2025-01-06T08:44:03.286443Z","iopub.status.idle":"2025-01-06T08:44:03.302815Z","shell.execute_reply.started":"2025-01-06T08:44:03.286418Z","shell.execute_reply":"2025-01-06T08:44:03.301994Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"filtered_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.303590Z","iopub.execute_input":"2025-01-06T08:44:03.303877Z","iopub.status.idle":"2025-01-06T08:44:03.318432Z","shell.execute_reply.started":"2025-01-06T08:44:03.303847Z","shell.execute_reply":"2025-01-06T08:44:03.317789Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'label'],\n    num_rows: 28860\n})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"dataset['train'] = filtered_data\ndataset['validation'] = dataset['validation'].rename_column('intent', 'label')\ndataset['test'] = dataset['test'].rename_column('intent', 'label')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.321937Z","iopub.execute_input":"2025-01-06T08:44:03.322151Z","iopub.status.idle":"2025-01-06T08:44:03.337523Z","shell.execute_reply.started":"2025-01-06T08:44:03.322132Z","shell.execute_reply":"2025-01-06T08:44:03.336850Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.338730Z","iopub.execute_input":"2025-01-06T08:44:03.338937Z","iopub.status.idle":"2025-01-06T08:44:03.355339Z","shell.execute_reply.started":"2025-01-06T08:44:03.338918Z","shell.execute_reply":"2025-01-06T08:44:03.354718Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 28860\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 3000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4500\n    })\n})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.356106Z","iopub.execute_input":"2025-01-06T08:44:03.356300Z","iopub.status.idle":"2025-01-06T08:44:03.373759Z","shell.execute_reply.started":"2025-01-06T08:44:03.356277Z","shell.execute_reply":"2025-01-06T08:44:03.372755Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 28860\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 3000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 4500\n    })\n})"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"model_name = \"roberta-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:03.374539Z","iopub.execute_input":"2025-01-06T08:44:03.374832Z","iopub.status.idle":"2025-01-06T08:44:05.375711Z","shell.execute_reply.started":"2025-01-06T08:44:03.374809Z","shell.execute_reply":"2025-01-06T08:44:05.374720Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c422dc1891c8495ab5b667bd456656f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac82b3ee67f4bc2ad8a151259e6f64e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"430878cd63964125b42d414ea86afe48"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b391a394e0aa47858f50f5ec82d1fcdd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4cbb06e6d184b7e8dce8f12198bc523"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\ndataset = dataset.map(tokenize, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:05.376453Z","iopub.execute_input":"2025-01-06T08:44:05.376712Z","iopub.status.idle":"2025-01-06T08:44:09.604422Z","shell.execute_reply.started":"2025-01-06T08:44:05.376691Z","shell.execute_reply":"2025-01-06T08:44:09.603366Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/28860 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"84c8843b43914622a3e2c2ee7a85b9e1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c1c3929f9494aebad7bcc907285e7cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/4500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa490d5bc1b9498bb5797050340aed91"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"keep_columns = [\"input_ids\", \"attention_mask\", \"label\"]\ndataset.set_format(\"numpy\", columns=keep_columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:09.605470Z","iopub.execute_input":"2025-01-06T08:44:09.605804Z","iopub.status.idle":"2025-01-06T08:44:09.611224Z","shell.execute_reply.started":"2025-01-06T08:44:09.605781Z","shell.execute_reply":"2025-01-06T08:44:09.610321Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"BATCH_SIZE = 16\n\ndef to_tf_dataset(hf_dataset, shuffle=False):\n    \"\"\"Convert a Hugging Face Dataset split into a tf.data.Dataset (features, label).\"\"\"\n    input_ids = hf_dataset[\"input_ids\"]\n    attention_mask = hf_dataset[\"attention_mask\"]\n    labels = hf_dataset[\"label\"]\n\n    # Commented out: \"token_type_ids\" (was used for BERT, not needed for RoBERTa),\n    # RoBERTa typically doesn't use token_type_ids, so it's often absent.\n    # token_type_ids = hf_dataset[\"token_type_ids\"]\n\n    ds = tf.data.Dataset.from_tensor_slices((\n        {\n            \"input_ids\": input_ids,\n            \"attention_mask\": attention_mask,\n            # \"token_type_ids\": token_type_ids,  # roberta does not need\n        },\n        labels\n    ))\n\n    if shuffle:\n        ds = ds.shuffle(10000)\n    ds = ds.batch(BATCH_SIZE)\n    return ds\n\ntrain_tf_dataset = to_tf_dataset(dataset[\"train\"], shuffle=True)\nval_tf_dataset   = to_tf_dataset(dataset[\"validation\"], shuffle=False)\ntest_tf_dataset  = to_tf_dataset(dataset[\"test\"], shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:09.612207Z","iopub.execute_input":"2025-01-06T08:44:09.612536Z","iopub.status.idle":"2025-01-06T08:44:10.495246Z","shell.execute_reply.started":"2025-01-06T08:44:09.612505Z","shell.execute_reply":"2025-01-06T08:44:10.494552Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"num_labels=150\nlr=1e-5\nnum_epochs=40\nmodel = TFAutoModelForSequenceClassification.from_pretrained(\n    model_name, \n    num_labels=num_labels\n)\n# AdamW from tensorflow\noptimizer = tf.keras.optimizers.AdamW(learning_rate=lr, weight_decay=0.01)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:10.496087Z","iopub.execute_input":"2025-01-06T08:44:10.496305Z","iopub.status.idle":"2025-01-06T08:44:16.527638Z","shell.execute_reply.started":"2025-01-06T08:44:10.496286Z","shell.execute_reply":"2025-01-06T08:44:16.526706Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a04805fc4c894929ab135b257d34a949"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"model.compile(\n    optimizer=optimizer,\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:16.528665Z","iopub.execute_input":"2025-01-06T08:44:16.528988Z","iopub.status.idle":"2025-01-06T08:44:16.545105Z","shell.execute_reply.started":"2025-01-06T08:44:16.528957Z","shell.execute_reply":"2025-01-06T08:44:16.544331Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Train\nhistory = model.fit(\n    train_tf_dataset,\n    validation_data=val_tf_dataset,\n    epochs=num_epochs\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-06T08:44:16.545901Z","iopub.execute_input":"2025-01-06T08:44:16.546154Z","execution_failed":"2025-01-06T17:26:03.163Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/40\n1804/1804 [==============================] - 1096s 585ms/step - loss: 3.9117 - accuracy: 0.3694 - val_loss: 1.9363 - val_accuracy: 0.8100\nEpoch 2/40\n1804/1804 [==============================] - 1045s 579ms/step - loss: 2.4766 - accuracy: 0.5876 - val_loss: 0.6959 - val_accuracy: 0.9347\nEpoch 3/40\n1804/1804 [==============================] - 1042s 578ms/step - loss: 1.8908 - accuracy: 0.6346 - val_loss: 0.3622 - val_accuracy: 0.9520\nEpoch 4/40\n1804/1804 [==============================] - 1043s 578ms/step - loss: 1.6353 - accuracy: 0.6609 - val_loss: 0.2474 - val_accuracy: 0.9657\nEpoch 5/40\n1804/1804 [==============================] - 1041s 577ms/step - loss: 1.4753 - accuracy: 0.6814 - val_loss: 0.1990 - val_accuracy: 0.9683\nEpoch 6/40\n1804/1804 [==============================] - 1041s 577ms/step - loss: 1.3472 - accuracy: 0.7037 - val_loss: 0.1928 - val_accuracy: 0.9623\nEpoch 7/40\n1804/1804 [==============================] - 1043s 578ms/step - loss: 1.2351 - accuracy: 0.7217 - val_loss: 0.1795 - val_accuracy: 0.9663\nEpoch 8/40\n1804/1804 [==============================] - 1041s 577ms/step - loss: 1.1165 - accuracy: 0.7466 - val_loss: 0.1715 - val_accuracy: 0.9680\nEpoch 9/40\n1804/1804 [==============================] - 1045s 579ms/step - loss: 1.0116 - accuracy: 0.7687 - val_loss: 0.1673 - val_accuracy: 0.9713\nEpoch 10/40\n1804/1804 [==============================] - 1042s 578ms/step - loss: 0.8985 - accuracy: 0.7935 - val_loss: 0.1682 - val_accuracy: 0.9673\nEpoch 11/40\n1804/1804 [==============================] - 1041s 577ms/step - loss: 0.7942 - accuracy: 0.8191 - val_loss: 0.1685 - val_accuracy: 0.9670\nEpoch 12/40\n1804/1804 [==============================] - 1040s 576ms/step - loss: 0.7047 - accuracy: 0.8385 - val_loss: 0.1697 - val_accuracy: 0.9683\nEpoch 13/40\n1804/1804 [==============================] - 1040s 577ms/step - loss: 0.6193 - accuracy: 0.8595 - val_loss: 0.1768 - val_accuracy: 0.9677\nEpoch 14/40\n1804/1804 [==============================] - 1037s 575ms/step - loss: 0.5461 - accuracy: 0.8785 - val_loss: 0.1819 - val_accuracy: 0.9643\nEpoch 15/40\n1804/1804 [==============================] - 1041s 577ms/step - loss: 0.4848 - accuracy: 0.8915 - val_loss: 0.1821 - val_accuracy: 0.9670\nEpoch 16/40\n1804/1804 [==============================] - 1043s 578ms/step - loss: 0.4322 - accuracy: 0.9043 - val_loss: 0.1896 - val_accuracy: 0.9667\nEpoch 17/40\n1804/1804 [==============================] - 1040s 576ms/step - loss: 0.3929 - accuracy: 0.9143 - val_loss: 0.1873 - val_accuracy: 0.9667\nEpoch 18/40\n1804/1804 [==============================] - 1039s 576ms/step - loss: 0.3537 - accuracy: 0.9235 - val_loss: 0.1848 - val_accuracy: 0.9690\nEpoch 19/40\n1804/1804 [==============================] - 1043s 578ms/step - loss: 0.3297 - accuracy: 0.9279 - val_loss: 0.2117 - val_accuracy: 0.9620\nEpoch 20/40\n1804/1804 [==============================] - 1038s 575ms/step - loss: 0.3087 - accuracy: 0.9317 - val_loss: 0.1781 - val_accuracy: 0.9693\nEpoch 21/40\n1804/1804 [==============================] - 1035s 574ms/step - loss: 0.2966 - accuracy: 0.9346 - val_loss: 0.1937 - val_accuracy: 0.9660\nEpoch 22/40\n1804/1804 [==============================] - 1035s 574ms/step - loss: 0.2834 - accuracy: 0.9375 - val_loss: 0.1895 - val_accuracy: 0.9673\nEpoch 23/40\n1804/1804 [==============================] - 1035s 573ms/step - loss: 0.2785 - accuracy: 0.9381 - val_loss: 0.2285 - val_accuracy: 0.9613\nEpoch 24/40\n1804/1804 [==============================] - 1035s 574ms/step - loss: 0.2746 - accuracy: 0.9380 - val_loss: 0.2196 - val_accuracy: 0.9647\nEpoch 25/40\n1804/1804 [==============================] - 1038s 576ms/step - loss: 0.2603 - accuracy: 0.9418 - val_loss: 0.2093 - val_accuracy: 0.9633\nEpoch 26/40\n1804/1804 [==============================] - 1039s 576ms/step - loss: 0.2617 - accuracy: 0.9410 - val_loss: 0.2129 - val_accuracy: 0.9653\nEpoch 27/40\n1712/1804 [===========================>..] - ETA: 50s - loss: 0.2505 - accuracy: 0.9426","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"model.evaluate(test_tf_dataset)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-06T17:26:03.165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output_dir = \"/kaggle/working/fine_tuned_roberta_40epoch\"\n\n# Save model and tokenizer\nmodel.save_pretrained(output_dir)\ntokenizer.save_pretrained(output_dir)\n\nprint(f\"Model and tokenizer saved to {output_dir}\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-06T17:26:03.165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\n\nshutil.make_archive(\"fine_tuned_roberta\", 'zip', output_dir)\nprint(\"Zipped model saved as fine_tuned_roberta.zip\")\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-06T17:26:03.165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification, AutoTokenizer\n# Load the model\nmodel = AutoModelForSequenceClassification.from_pretrained(output_dir, from_tf=True)\ntokenizer = AutoTokenizer.from_pretrained(output_dir, from_tf=True)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-06T17:26:03.165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport tensorflow as tf\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.metrics import precision_score, recall_score, accuracy_score, confusion_matrix\ndef evaluate_model_with_cm(model, test_dataset, num_classes=150):\n    \"\"\"\n    Evaluate the model with corrected per-class accuracy calculation.\n    \"\"\"\n    # Set model to evaluation mode\n    model.eval()\n    \n    # Lists to store predictions and true labels\n    all_predictions = []\n    all_labels = []\n    \n    # Disable gradient calculations for inference\n    with torch.no_grad():\n        for batch in tqdm(test_dataset, desc=\"Evaluating\"):\n            inputs = batch[0]\n            labels = batch[1]\n            \n            device = next(model.parameters()).device\n            input_dict = {\n                'input_ids': torch.tensor(inputs['input_ids'].numpy()).to(device),\n                'attention_mask': torch.tensor(inputs['attention_mask'].numpy()).to(device)\n            }\n            \n            outputs = model(**input_dict)\n            logits = outputs.logits\n            predictions = torch.argmax(logits, dim=1).cpu().numpy()\n            \n            all_predictions.extend(predictions)\n            all_labels.extend(labels.numpy())\n    \n    # Convert to numpy arrays\n    all_predictions = np.array(all_predictions)\n    all_labels = np.array(all_labels)\n    \n    # Calculate general metrics\n    metrics = {\n        'accuracy': accuracy_score(all_labels, all_predictions),\n        'f1_macro': f1_score(all_labels, all_predictions, average='macro'),\n        'precision_macro': precision_score(all_labels, all_predictions, average='macro'),\n        'recall_macro': recall_score(all_labels, all_predictions, average='macro')\n    }\n    \n    # Calculate full confusion matrix\n    full_cm = confusion_matrix(all_labels, all_predictions)\n    metrics['full_confusion_matrix'] = full_cm\n    \n    # Calculate per-class metrics\n    class_metrics = []\n    for i in range(num_classes):\n        # Get indices for this class\n        class_mask = (all_labels == i)\n        if np.any(class_mask):\n            # Get predictions and true labels for this class\n            class_preds = all_predictions[class_mask]\n            class_true = all_labels[class_mask]\n            \n            # Calculate metrics for this class\n            class_acc = accuracy_score(class_true, class_preds)\n            \n            # Calculate precision and recall for this class\n            class_precision = precision_score(all_labels == i, all_predictions == i)\n            class_recall = recall_score(all_labels == i, all_predictions == i)\n            \n            # Store all metrics\n            class_metrics.append({\n                'class_id': i,\n                'accuracy': class_acc,\n                'precision': class_precision,\n                'recall': class_recall,\n                'support': np.sum(class_mask)  # number of samples for this class\n            })\n    \n    # Sort classes by accuracy\n    sorted_classes = sorted(class_metrics, key=lambda x: x['accuracy'])\n    \n    # Get worst, middle, and best performing classes\n    worst_class = sorted_classes[0]\n    middle_class = sorted_classes[len(sorted_classes)//2]\n    best_class = sorted_classes[-1]\n    \n    # Calculate confusion matrices for selected classes\n    def get_binary_confusion_matrix(true_labels, pred_labels, target_class):\n        \"\"\"Convert multi-class labels to binary for one specific class\"\"\"\n        true_binary = (true_labels == target_class).astype(int)\n        pred_binary = (pred_labels == target_class).astype(int)\n        return confusion_matrix(true_binary, pred_binary)\n    \n    selected_cms = {\n        'worst_class': {\n            'class_id': worst_class['class_id'],\n            'accuracy': worst_class['accuracy'],\n            'precision': worst_class['precision'],\n            'recall': worst_class['recall'],\n            'support': worst_class['support'],\n            'confusion_matrix': get_binary_confusion_matrix(all_labels, all_predictions, worst_class['class_id'])\n        },\n        'middle_class': {\n            'class_id': middle_class['class_id'],\n            'accuracy': middle_class['accuracy'],\n            'precision': middle_class['precision'],\n            'recall': middle_class['recall'],\n            'support': middle_class['support'],\n            'confusion_matrix': get_binary_confusion_matrix(all_labels, all_predictions, middle_class['class_id'])\n        },\n        'best_class': {\n            'class_id': best_class['class_id'],\n            'accuracy': best_class['accuracy'],\n            'precision': best_class['precision'],\n            'recall': best_class['recall'],\n            'support': best_class['support'],\n            'confusion_matrix': get_binary_confusion_matrix(all_labels, all_predictions, best_class['class_id'])\n        }\n    }\n    \n    metrics['selected_confusion_matrices'] = selected_cms\n    metrics['class_metrics'] = sorted_classes\n    \n    return metrics\n\ndef print_class_details(metrics, class_type):\n    \"\"\"Print detailed metrics for a specific class.\"\"\"\n    class_info = metrics['selected_confusion_matrices'][class_type]\n    cm = class_info['confusion_matrix']\n    \n    print(f\"\\n{class_type.upper()} CLASS (ID: {class_info['class_id']}):\")\n    print(f\"Accuracy: {class_info['accuracy']:.4f}\")\n    print(f\"Precision: {class_info['precision']:.4f}\")\n    print(f\"Recall: {class_info['recall']:.4f}\")\n    print(f\"Number of samples: {class_info['support']}\")\n    print(\"\\nConfusion Matrix:\")\n    print(f\"TN: {cm[0,0]}, FP: {cm[0,1]}\")\n    print(f\"FN: {cm[1,0]}, TP: {cm[1,1]}\")\n\nroberta_results = evaluate_model_with_cm(model, test_tf_dataset)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-06T17:26:03.165Z"}},"outputs":[],"execution_count":null}]}